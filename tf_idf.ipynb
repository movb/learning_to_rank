{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for query_id, docs in test_test_data:\n",
    "    query = queries[query_id]\n",
    "    for doc_id in docs:\n",
    "        scores = get_tf_idf(query, doc_id, bm25_model)\n",
    "        temp = [query_id, doc_id]\n",
    "        for x in scores:\n",
    "            for y in x:\n",
    "                temp.append(y)\n",
    "        results.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tf_idf(query, doc_id, model):\n",
    "    title, body = utils.get_document(fd, index, doc_id)\n",
    "    \n",
    "    query_terms = set(query.strip().split(' '))\n",
    "    title_terms = Counter(title.strip().split(' '))\n",
    "    body_terms = Counter(body.strip().split(' '))\n",
    "    whole_terms = title_terms + body_terms\n",
    "    \n",
    "    def get_tfs(query_terms, doc_terms):\n",
    "        intersection = query_terms.intersection(set(doc_terms.keys()))\n",
    "        tfs = {}\n",
    "        for term in intersection:\n",
    "            tfs[term] = doc_terms[term]\n",
    "        return tfs\n",
    "            \n",
    "    def get_tfs_counts(tfs):\n",
    "        values = list(tfs.values())\n",
    "        sum_tfs = np.sum(values)\n",
    "        min_tf = np.min(values)\n",
    "        max_tf = np.max(values)\n",
    "        mean_tf = np.mean(values)\n",
    "        std_tf = np.std(values)\n",
    "        \n",
    "        return sum_tfs, min_tf, max_tf, mean_tf, std_tf\n",
    "        \n",
    "    def get_tfs_normalized(tfs, term_count):\n",
    "        tfs = np.array(list(tfs.values())) / term_count\n",
    "        \n",
    "        sum_tfs = np.sum(tfs)\n",
    "        min_tf = np.min(tfs)\n",
    "        max_tf = np.max(tfs)\n",
    "        mean_tf = np.mean(tfs)\n",
    "        std_tf = np.std(tfs)\n",
    "        \n",
    "        return sum_tfs, min_tf, max_tf, mean_tf, std_tf\n",
    "    \n",
    "    def get_tf_idf(tfs, term_count, terms_docs):\n",
    "        for x in list(tfs.keys()):\n",
    "            tfs[x] = tfs[x]/term_count\n",
    "            \n",
    "        def idf(term, tf):\n",
    "            if not term in terms_docs:\n",
    "                return 0\n",
    "            return tf*model.idf2(len(terms_docs[term]))\n",
    "        \n",
    "        tfidfs = []\n",
    "        for term, tf in tfs.items():\n",
    "            tfidfs.append(idf(term,tf))\n",
    "            \n",
    "        sum_tfidfs = np.sum(tfidfs)\n",
    "        min_tfidf = np.min(tfidfs)\n",
    "        max_tfidf = np.max(tfidfs)\n",
    "        mean_tfidf = np.mean(tfidfs)\n",
    "        std_tfidf = np.std(tfidfs)\n",
    "                          \n",
    "        return  sum_tfidfs, min_tfidf, max_tfidf, mean_tfidf, std_tfidf\n",
    "    \n",
    "    title_terms_count = sum(list(title_terms.values()))\n",
    "    body_terms_count = sum(list(body_terms.values()))\n",
    "    whole_terms_count = sum(list(whole_terms.values()))\n",
    "    \n",
    "    title_term_docs = model.term_to_title\n",
    "    body_term_docs = model.term_to_body\n",
    "    whole_term_docs = title_term_docs.copy()\n",
    "    whole_term_docs.update(body_term_docs)\n",
    "    for term in whole_term_docs.keys():\n",
    "        whole_term_docs[term] = list(set(whole_term_docs[term]))\n",
    "    \n",
    "    title_tfs = get_tfs(query_terms, title_terms)\n",
    "    title_tfs_counts = get_tfs_counts(title_tfs)\n",
    "    title_tfs_normalized = get_tfs_normalized(title_tfs, title_terms_count)\n",
    "    title_tf_idfs = get_tf_idf(title_tfs, title_terms_count, title_term_docs)\n",
    "    \n",
    "    body_tfs = get_tfs(query_terms, body_terms)\n",
    "    body_tfs_counts = get_tfs_counts(body_tfs)\n",
    "    body_tfs_normalized = get_tfs_normalized(body_tfs, body_terms_count)\n",
    "    body_tf_idfs = get_tf_idf(body_tfs, body_terms_count, body_term_docs)\n",
    "    \n",
    "    whole_tfs = get_tfs(query_terms, whole_terms)\n",
    "    whole_tfs_counts = get_tfs_counts(whole_tfs)\n",
    "    whole_tfs_normalized = get_tfs_normalized(whole_tfs, whole_terms_count)\n",
    "    whole_tf_idfs = get_tf_idf(whole_tfs, whole_terms_count, whole_term_docs)\n",
    "    \n",
    "    return (title_tfs, title_tfs_counts, title_tfs_normalized, title_tf_idfs, body_tfs, body_tfs_counts,\n",
    "            body_tfs_normalized, body_tf_idfs, whole_tfs, whole_tfs_counts, whole_tfs_normalized, whole_tf_idfs)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:work]",
   "language": "python",
   "name": "conda-env-work-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
